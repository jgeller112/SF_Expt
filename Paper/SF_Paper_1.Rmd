---
title: "Sans Forgetica is not desirable for learning"
author:
- address: 'Department of Psychological and Brain Science, W113 Seashore Hall, Iowa City, IA, 52242'
  affiliation: '1'
  corresponding: yes
  email: jason-geller@uiowa.edu
  name: Jason Geller
- affiliation: '2'
  name: Sara D. Davis
- affiliation: '2'
  name: Daniel Peterson
affiliation:
- id: '1'
  institution: University of Iowa
- id: '2'
  institution: Skidmore College
output: papaja::apa6_word
bibliography: ref.bib
classoption: "doc"
documentclass: "apa6"
draft: no
figurelist: no
floatsintext: no
footnotelist: no
keywords: Disfluency, Recall, Desirable Difficulty, Learning and Memory
linenumbers: yes
mask: no
authornote: |
  Jason Geller, Department of Psychology and Brain Sciences, University of Iowa, W113 Seashore Hall, Iowa City, IA, 52242;
shorttitle: Sans Forgetica
tablelist: no
abstract: "Do students learn better with material that is perceptually harder to process?
  While evidence is equivocal on the matter, recent claims suggest that placing materials
  in Sans Forgetica font, which is perceptually hard to process, has positive effects
  on student learning. Given the weak evidence for perceptual disfluency effects,
  this led us to examine the mnnmonic effects of Sans Forgetica more closely. In three
  preregistered experiments, we tested if Sans Forgetica is really unforgetable. In
  Experiment 1 (*N* = 233), participants studied weakly realted cue-target pairs with
  targets presented in either Sans Forgetcia or with missing letters (e.g., G_RL).
  Cued recall performance showed a robust generation effect, but no Sans Forgetica
  memory benefit. In Experiment 2 (*N*=528), participants read a passage about ground
  water with select sentences presented in either Sans Forgetcia, yellow highlighting,
  or unmodified. Cued recall for select words were better for pre-highlighted information
  than when unmodified. Critically, presenting sentences in Sans Forgetica did not
  produce better cued recall than pre-highlighted sentences or sentences presented
  unchanged. In Experiment 3 (*N* = 60), indiviudals did not have better discriminabiliy for Sans Forgetic in an old-new recognition test. Our findings   suggest that Sans Forgetica really is forgeticable."
wordcount: 4458
---

```{r setup, include = FALSE}
library("papaja")
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```

Students want to remember more and forget less. Being able to recall and apply previously learned information is key for successful learning. Decades of research in the laboratory and in the classroom have put forth the paradoxical idea that making learning harder (not easier) should have the desirable effect of improving long-term retention of material--called the desirable difficulty principle [@Bjork2011]. Notable examples of desirable difficulties include having participants generate information from word fragments instead of passively reading intact words [@Bertsch2007], spacing out study sessions instead of massing them [@Carpenter2016], and having participants engage in retrieval practice after studying instead of simply restudying the information [@Kornell2016]. Another simple strategy that has gained some attention is to make material more perceptually disfluent. This can be done by changing the material’s perceptual characteristics. Visual material that is masked [@Mulligan1996], inverted [@Sungkhasettee2011], presented in an atypical font [@Diemand-Yauman2011; @French2013], blurred [@Rosner2015], or even in handwritten cursive [@Geller2018] have all been shown to produce memory benefits. The desirable effect of perceptual disfluency on memory is called the disfluency effect [@Bjork2016]. 

Although appealing as a pedagogical strategy due to the relative ease of implementation, there have been several experiments that failed to find memorial benefits for perceptually disfluent materials [e.g., @Magreehan2016; @Rhodes2008, @Rhodes2009; @Rummer2016; @Yue2013], casting doubt upon the robustness of the disfluency effect. Corroborating this, A recent meta-analysis by @Xie2018 with 25 studies and 3,135 participants found a small, non-significant, effect of perceptual disfluency on recall and (*d* = -0.01) and transfer (*d* = 0.03). Despite having no mnemonic effect, perceptual disfluency produced longer reading times (*d* = 0.52) and lower judgments of learning (*d* =  -0.043). In the laboratory, @Geller2018 and Geller & Still (2018) manipulated several boundary conditions (e.g., level of degradation (easy-to-read vs. hard-to-read), type of judgement of learning (list-wise vs item-by-item), retention interval (3 minites vs. 24-hours), and testing expectancy(incidental vs. intentional)) and found you can get positive memory effects from perceptual disfluent materials (in recognition), but it is not robust. Taken together, the evidence is weak for perceptual disfluency being a desirable difficulty. 

Despite the weak evidence, perceptual disfluency is still being touted as a viable learning tool. Most recently, a font called Sans Forgetica has recieved a lot of attention for its purported positive effects on memory. Sans Forgteica is a variation of a sans-serif typeface that consists of intermittent gaps in letters that are back slanted (see fig. 1). These perceptual characteristics are thought to make it desirable for learning.Indeed, Major news sources like the Washington Post [@Telford2018] and National Public Radio (NPR; https://www.npr.org/2018/10/06/655121384/sans-forgetica-a-font-to-remember) have reported on the positive effects of Sans Forgetica on memory. The Sans Forgetica font is even available on multiple operating platforms. 

# What do we know about Sans Forgetica?


```{r, fig.cap=paste("Example of Sans Forgetica font. ")}
library(here)
knitr::include_graphics(here('SF.png'))
```	

With all this positive attention Sans Forgetica is receiving, there must be strong evidence? Currently, there are only few unpublsihed and published reports garnering support for Sans Forgetica as a desirbale difficulty [@Earp2018; @Eskenazi2020]. 

In two unpublished studies conducted by the creators of Sans Forgetica. In a lab experiment (*N*=96), participants read 20 word highly associated word pairs (e.g., girl - guy) in one of them being Sans Forgetica) and a typical or common font. The font pairs were presented were counterbalanced across participants. What this means is that all fonts were shown, but the same pairs were never presneted in more than one type of font. Each word pair was presnted on the screen for 100 ms (that is super fast...). For a final test, they were given the cue (e.g., *girl*) and had to respond with the target (*guy*). What did they find? According to the interview, targets were recalled 68% of time when presented in a common font. For cue-target pairs in SF, targets were recalled 69% of the time--a negeliable difference. 

In an online experiment, participants were presented passages (250 words in total) where one of the paragraphs was presented in SF. Each participant saw five different texts in total. For each text they were asked one question about the part written in SF and another question about the part written in standard Arial. Participants remembered 57% of the text when a section was written in Sans Forgetica, compared to 50% of the surrounding text that was written in a plain Arial font.


## Current Studies

Given the weak evidence for the disfluency effect, we thought it pertinent to empirically examine whether Sans Forgetica produces more durable learning. The question of whether Sans Forgetica produces a mnnmenomic benefits has clear practical implications. In the educational domain, it would be relatively quick and easy to place materials in Sans Forgetica font. However, in order for the Sans Forgetica to be useful, it is important to note and understand both its successes and failures. To the authors' knowledge, there has only been two empirical studies published examining the effectviness of Sans Forgetica in generating a desirable difficulty [@Eskenazi2020]. In a successful replication, @Eskenazi2020 found that words and definitions in Sans Forgetica font lead to better orthographic discriminabity (i.e., choosing the correct spelling of the word) and semantic acquisition (i.e., retrieving the definition of a word), but only if participants were good spellers. As the Eskenazi and Nix (2020) study focused on lexical acquisition (learning orthographic and semantic features of a word), it is not clear if the benefits of Sans Forgetica font extends to other memory processes. @fuck provide some evidence that it does not. In conduceted one of the first set of empirical studies examining the Sans Forgetica memory benfit across  several experiments showing no effect for Sans Forgetica in paired-assoicate cued recall and prose recall. In three high-powered pre-registered studies, we conducted conceptual repliactions and extensions of oftheir findings. Expeiments 1 and 2 served to conceptual replicate their findings. In Experiment 3, we extend these findings to recognition memory. In addition, we aimed to compared the Sans forgetica effect with other notable learning technqies--generation (Experiment 1) and pre-highlighting (Experiment 2). Comparing Sans Forgetica to other study techniques allows us to examine the mechanisms underlying the effect, if any. 

# Experiment 1

In Experiment 1 we were interested in answering two questions. First, is Sans Forgetica more memorable than a normal, fluent, font (e.g., Arial)? Second, is the Sans Forgetica effect on memory similar in magnitude to the generation effect? While very is known about Sans Forgetica, one of the most intuitively appealing theories for why Sans Forgetica font benefits memory is that of mental effort. It is believed that reading materials in Sans Forgetica requires more effort than simply reading a normal font. Essentially, the intermittent gaps of Sans Forgetica requires readers to generate or fill in the missing pieces producing a memory advantage. This mechanism of action is similar to that of the generation effect, wherein information is better remembered when generated or filled-in compared to if it is simply read. In Experiment 1 we examined the mnemonic benefit of Sans Forgetica and generation by looking at cued recall performance While @fuck  examined the effect of Sans Forgetica font on cued-recall memory using highly associated words, we used wealkly assoicated word pairs. It is possible that @fuck failed to find a Sans Forgetica effect because of the high cue strength. With highly associated paris, successful retreial is due to the highly associated nature of the pairs, and not recollection processes per se. To this end we use weakly associated pairs to examine the effect of Sans forgetica and generation on memory. We predict that if Sans Forgetica does produce a mnemonic benefit, we should observe better cued recall performance for targets in Sans forgetica font compared to Arial font. Further, if it is similar to the generation effect, the magnitude of the memory benefit between the two should be similar. 

## Method

### Participants

We report how we determined our sample size, all data exclusions, all inclusion/exclusion criteria, whether inclusion/exclusion criteria were established prior to data analysis, all manipulations, and all measures in the study. Two-hundred and thirty people from Amazon’s Mechanical Turk Service participated for money. Sample size was based on a priori power analyses conducted using PANGEA v0.2 (Westfall, 2015). Sample size was calculated based on the smallest effect of interest [SEOI; @Lakens2014]. In this case, we were interested in powering our study to detect a medium sized interaction effect (*d* = .35). We choose this effect size as our SESOI due in part to the small effect sizes seen in actual classroom studies [@Butler2014]. Therefore, assuming an alpha of .05 and  a desired power of 90%, a sample size of 230 is required to detect whether an effect size of .35 differs from zero. After excluding participants who 1) did not complete every phase of the experiment, 2) started the experiment multiple times, 3) reported experiencing technical problems did not indicate that they were fluent in English [^2]: This question was not asked during the experiment., or 5) reported seeing our stimuli before, we were left with 115 participants per group. 

### Materials

The preregistration for Experiment 1 can be found here: https://aspredicted.org/3ai98.pdf.  All materials, data, and analysis scripts for both Experiment 1 can be found here (https://osf.io/d2vy8/). The results contained herein are computationally reproducible by going to the primary author's github repository for the paper (https://github.com/jgeller112/SF_Expt2) and clicking on the binder button.

Participants were presented with 24 weakly related cue-target pairs taken from @Carpenter2006) [^1]: Two cue-target pairs (e.g., range-rifle and train-plane) had to be thrown out as they were not presented due to a coding error. This left us with 22 weakly realted cue-target pairs. The cue-target pairs were all nouns, 5–7 letters and 1–3 syllables in length, and high in concreteness (400–700) and frequency (at least 30 per million). Free association norms [@Nelson2004] were used to create 22 weakly associated pairs of similar forward and backward strength. Two counterbalanced lists were created for each difficulty type group(generation and Sans Forgetica) so that each item could be presented in each disfluency conditions without repeating any items for an individual participant. 

### Design and Procedure

Disfluency (fluent vs. disfluent) was manipulated within-subjects and within-items and difficulty type (Generation vs. Sans Forgetcia) was manipulated between participants. For half the participants, targets were presented in Sans Forgetica while the other half were presented in Arial font; for the other half of participants, targets were presented with missing letters (vowels were replaced by underscores) and the other half were intact (Arial font). After a short 2 minute distraction task (anagram generation), they completed a cued recall test. During cued recall, participants were presented 24 cues one at a time and asked to provide the target word. After they were thanked and debriefed. 

Participants completed the experiment on-line via the Qualtrics survey platform hosted on Amazon Mechanical Turk. After reading and consenting, participants were randomly assigned to one of two conditions: The generation condition or the Sans Forgetica condition. Participants were told to study word pairs so that later they could recall the second word (target) when cued with the first word (cue). The experiment began with the presentation of 22 word pairs, shown one at a time, for 2 seconds each. The cue word always appeared on the left and the target always on the right. Immediately proceeding this, participants did a short 2 minute distraction task (anagram generation). Finally, participants completed a cued recall test. During cued recall, participants were presented 22 cues one at a time and asked to provide the target word. Responses were self-paced. Once completed, participants clicked on a button to advance to the next question. At the end, participants were asked several demographic questions.

### Scoring

Spell checking was automated with the hunspell package in R [@Ooms2018] using spellCheck.R. Because participants were recruited in the United States, we used the American English dictionary. A nice walk-through on how to use this package can be found in @Buchanan2019. Using this package, each response was corrected for misspellings. Corrected spellings are provided in the most probable order, therefore, the first suggestion was always selected as the correct answer. As a second pass, we manually examined the output to catch incorrect suggestions. If the response was close to the correct response, it was marked as correct.

### Analysis

For all experiments, an alpha level of .05 was used for significance testing. Cohen's d and generalzied eta-squared are reported as effect-size measures. In addition, for all null findings, Bayes factors (with default priors), are calculated. A Bayes factors of 3 or greater is indicative of strong or positive evidence in favor of the null (Jefferys, 1961). DAll data were analyzed in R (vers. 3.5.0; R Core Team, 2019), with models fit using the afex [vers. 0.27-2; @Singmann2020] and BayesFactor packages [vers. 0.9.12-4.2; @Morey2018].


# Results and Discussion

Per our pregreistation, cued-recall accuracy was analyzed with a A 2 (DT) x 2 () Mixed ANOVA. There was no difference in cued recall between the Generation and Sans Forgetica groups, *F*(1, 230) = 0.19, ges=<.001, p = .661. *b* = -0.09, *SE* = 0.11, 95% CI [-0.30, 0.13], *p* = 0.431, *d* = 0.05). Individuals recalled more disfluent target words than fluency target words, *F*(1, 230) = 25.31, ges=.017, *p* < .001. This was qualified by an interaction between difficulty type and disfluency, *F*(1, 230) = 25.06, ges = .017, *p* < .001. A Bayesian ANOVA indicated strong evidence for the interaction model over the main effects model, BF~10~ > 100. As seen in Fig. 2, the magnitude of the generation effect was larger than the Sans Forgetica effect. 

```{r,fig.align="center",  fig.height=4, fig.width=8, fig.cap="Accuracy on cued recall test. Violin plots represent the kernal density of avearge accuracy(black dots) with the fixed effect mean (white dot) and 95\\% CIs derived from the glmer model.", warnings=FALSE, messages=FALSE, echo=FALSE, results="asis"}
library(qualtRics)
library(tidyverse)
library(effects)
library(here)
library(lme4)
library(ggpol)
library(knitr)
library(here)
library(BayesFactor)
### To install without vignettes (faster):
devtools::install_github("rvlenth/emmeans")
library(emmeans)
library(modelbased)
library(see)
sfgen=read_csv(here("Expt1_data", "sfgenerate_final.csv"))

#for the brms model
ex1=sfgen %>% mutate(difftype = case_when( 
        condition == "Generate" ~ 0.5, 
        condition=="Sans Forgetica" ~  -0.5, 
    ), disflu= case_when (
         dis == "fluent" ~ 0.5, 
         dis== "disfluent" ~ -0.5))

ex1_agg <- sfgen %>%
  group_by(ResponseID, condition, dis)%>%
  summarise(mean_acc=mean(acc))


a1 <- aov_ez("ResponseID", "mean_acc", ex1_agg, 
             between = c("condition"), within=c("dis")) # mixed

summary(a1)

x_label=c("Disfluent", "Fluent")

ls1 <-emmeans(a1, specs="dis", by="condition") 
ls1<-as.data.frame(ls1)

#BayesFactor evidence for Full (Main + Inter) vs. Main Effects model

bf = anovaBF(mean_acc ~ condition*dis + ResponseID, ex1_agg, 
             whichRandom="ResponseID")

b1comp=bf[4] /bf[3]

#Bayes factor analysis >100
#--------------
#[1] condition + dis + condition:dis + ResponseID : 12585.92 ±4.67%

#Against denominator:
 # mean_acc ~ condition + dis + ResponseID 
---
#Bayes factor type: BFlinearModel, JZS
  
#full_model=glmer(acc~condition*dis + (1+ dis|ResponseID) + (1+dis+condition|target), data=sfgen, contrasts = list(dis="contr.sum", condition="contr.sum"), #family="binomial", control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))


#eans<-estimate_means(full_model)


#ef1 <- effect("condition:dis", full_model) #take final glmer model 
#x1 <- as.data.frame(ef1)

bold <- element_text(face = "bold", color = "black", size = 14) #axis bold

#p<- ggplot(x1, aes(dis, fit, fill=dis))+ facet_grid(~condition)+ 
 # geom_bar(stat="identity", position="dodge") + 
 # geom_errorbar(aes(ymin=lower, ymax=upper), width=0.2, position=position_dodge(width=0.9),color="red") + theme_bw(base_size=14)+labs(y="Pr Recall", x="Disfluency") + 
#  theme(legend.position = "none") +
# scale_fill_manual(values=c("grey", "black")) + ggplot2::coord_cartesian(ylim = c(0, 1)) + theme(axis.text=bold)


p1<- ggplot(ex1_agg, aes(dis, mean_acc, fill=dis))+ facet_grid(~condition)+ 
  geom_violin() + 
  geom_jitter2(width=0.11, alpha=.5)+ 
  geom_line(data=ls1,aes(y=emmean, group=1), size=1)+ 
  geom_pointrange(data=ls1, aes(y=emmean, ymin=lower.CL, ymax=upper.CL), size=1, color="white")+ 
  scale_x_discrete(labels= x_label)+
  theme_bw(base_size=14)+labs(y="Proportion Recalled on Final Test", x="Disfluency") + 
  theme(legend.position = "none") + ggplot2::coord_cartesian(ylim = c(0, 1)) + theme(axis.text=bold) 


#m1<-read_rds(here("Brms", "brms1.rds.gz"))

#dis_inter <- emmeans(m1, ~ dis*condition, type="response")

#dis_plot=plot(dis_inter, horizontal=FALSE, by="condition", colors="darkgreen") + ggtitle ("Cued Recall Accuracy") + labs(x="Condition Type", y= "Probability Answering Question", subtitle = "95% HDI Intervals") + facet_grid(~condition) + theme_bw(base_size = 14) + ggplot2::coord_cartesian(ylim = c(0, 1)) + theme(axis.text=bold)

#dis_plot

p1

```

The results for Experiment 1 are clear-cut. Cued recall for Sans Forgetica font was similar to normal, Arial, font. Thus, there was no Sans Forgetica benefit. We did, however, observe greater recall for generated items, which replicates decades of literature on the generation effect [@Bertsch2007]. Taken together, these results suggest that (1) presenting materials in Sans Forgetica does not lead to better memory and (2) the Sans Forgetica effect is most likely not a desirable difficulty. 

# Experiment 2

Experiment 1 failed to find a memory benefit for Sans Forgetica effect. A limitation of Experiment 1 is that simple stimulus-response learning lacks educational realism. To remedy this, Experiment 2 tested the mnemonic effects of Sans Forgetica using more realistic materials. Whereas Experiment 1 tested whether Sans Forgetica is driven by the generative process of retrieval, Experiment 2 examined  whether the Sans Forgetcia effect might exert its mnemonic benefit by making material more distinctive. Specifically, Sans Forgetica may make the marked portion of text more memorable because it stands out from the surrounding text. This is similar to the effects of pre-highlighting on learning. Indeed, some evidence supports this type of role for highlighting: When students read pre-highlighted passages, they recall more of the highlighted information and less of the non-highlighted information compared to students who receive an unmarked copy of the same passage [@Fowler1974; @Silvers1997]. To this end, Experiment 2 compared cued recall performance on a passage where some of the sentences were either presented in: Sans Forgetica, pre-highlighted in yellow, or unmodified. We hypothesized that if the Sans Forgetica effect is mainly driven by distinctiveness, words presented in Sans Forgetica should benefit more from the disfluency than the passage presented unmodified. Further, the benefit for Sans Forgetica should be similar in magnitude to the pre-highlighting condition as both manipulations serve to increase the distinctiveness of the text. 

## Method

The pre-registration form for Experiment 2, which includes hypotheses, planned analyses,exclusion criteria, and sample size justification, can be found at: https://aspredicted.org/3jz3z.pdf.


### Participants

We report how we determined our sample size, all data exclusions, all inclusion/exclusion criteria, whether inclusion/exclusion criteria were established prior to data analysis, all manipulations, and all measures in the study. Five hundred and twenty-eight undergraduates (*N* = 528) participated for partial completion of course credit. Sample size was based on a priori power analyses conducted using PANGEA v0.2. Sample size was calculated based on the smallest effect of interest [@Lakens2014]. Similar to Experiment 1, we were interested in powering our study to detect a medium-sized effect size (*d* = .35). Therefore, assuming an alpha of .05 and  a desired power of 90%, a sample size of 170 per group is required to detect whether an effect size of .35 differs from zero. After excluding participants based on our preregistered exclusion criteria, we were left with unequal group sizes. Because of this, we ran six more participants per group, giving us 176 participants in each of the three conditions.

### Materials

All materials used for this experiment can be found on our OSF page (https://osf.io/d2vy8/) under the Expt 2 Stims folder.  Participants read a passage on ground water (856 words) taken from from the U.S. Geological Survey [see @Yue2014]. Eleven critical phrases [^2]: originally we had 12 critical phrases but a pilot test showed that one of the questions was repeated twice so we removed one of them and also added a manipulation check question to sure participants were paying attention] each containing a different keyword, were selected from the passage (e.g., the term *recharge* was the keyword in the phrase: Water seeping down from the land surface adds to the ground water and is called recharge water.) and were either presented in SF, highlighted, or unmodified. Then, 11 fill-in-the blank questions were created from these phrases by deleting the keyword and asking participants to provide it on the final test (e.g., Water seeping down from the land surface adds to the ground water and is called __________ water). There was 1 manipulation check question: "What was the passage you read on?."

### Design and Procedure

Participants were randomly assigned to either the pre-highlighted condition, Sans Forgetica condition, or unmodified condition. Our design manipulated three difference types of passages between-subjects: pre-highlighting, Sans Forgetica, and unmodified.

Participants completed the experiment on-line via the Qualtrics survey platform. After reading and signing a consent form, participants were randomly assigned to one of three conditions: pre-highlighting, Sans Forgetica, or unmodified. Participants read a passage on ground water. All participants were instructed to read the passage as though they were studying material for a class. After 10 minutes, all participants were given a brief questionnaire (2 questions) asking them to indicate their metacognitive beliefs after reading the passage. The two questions were: “Do you feel that the presentation of the material helped you remember it better" and "How likely is it that you will be able to recall material from the passage you just read on a scale of 0 (not likely to recall) to 100 (likely to recall) in 5 minutes?" Participants were then given a short distraction task (anagrams) for 3 minutes. Finally, all participants were given 12 fill-in-the-blank test questions, presented one at a time.

### Scoring

Spell checking was automated with the same procedure as Experiment 1.

## Results and Discussion

Per our pregreistation, cued-recall accuracy was analyzed with a one-way ANOVA (Passage Type: Pre-highlighting vs. Sans Forgetica vs. Unmodified). We hypothesized that recall for pre-highlighted and Sans Forgetica sentences would be better remembered than normal sentences and that there would be no recall differences between the highlighted and sans forgetia sentences. Our hypotheses were partially supported (see Fig. 2). Results indicated that pre-highlighted sentences were better remembered than sentences presented normally, *t*(525) = 2.45, *SE* = 0.028, *p* = .039, *d* = 0.26. There was weak evidence for no effect between sentences presented in Sans Forgetcia and pre-highlighted, *t*(525) = 0.049, *SE* = 0.028, *p* = .202, *d* = 0.18, BF~01~ = 2.36. Critically, there was no difference between sentences presented normally or in Sans Forgetcia, *t*(525) = 0.02, *SE* = 0.028, *p* = .734, *d* = 0.079. A Bayes factor indicated strong evidence of no effect between the two conditions (BF~01~ = 6.47). 


```{r, fig.align="center", fig.height=4, fig.width=8, fig.cap="Probablity of recall as a function of passage type. Violin plots represent the kernal density of avearge accuracy(black dots) with the fixed effect mean (white dot) and 95\\%  CIs derived from the ANOVA model.", messages=FALSE, echo=FALSE, warning=FALSE,  results="asis"}
library(qualtRics)
library(tidyverse)
library(afex)
library(emmeans)
library(here)
library(ggpol)
library(knitr)

ground <- qualtRics::read_survey(here("Expt2_Data", "memory_acc_gw_final.csv"))

ground_change <- ground %>%
  mutate(Passage=ifelse(FL_149_DO=="Highlight", "Pre-highlighted", ifelse(FL_149_DO=="Passage", "Sans Forgetica", "Unmodified")))

ground_change_agg<-ground_change %>%
  group_by(ResponseId, Passage) %>%
  summarise(mean_acc=mean(auto_acc))

#Classic ANOVA

a1 <- aov_ez("ResponseId", "mean_acc", ground_change_agg, 
             between = c("Passage")) # one way

ls1 <- emmeans(a1, specs = "Passage") # get the simple effects test for signifcant interaction. 



flex1=pairs(ls1)

effsexp2=eff_size(flex1, sigma = sigma(a1$lm), edf = 525, method = "identity")

ls1<-as.data.frame(ls1)

ground_change_agg$Passage <- factor(ground_change_agg$Passage, level=c("Pre-highlighted", "Unmodified", "Sans Forgetica"))     

bf1<- ground_change_agg %>%
  filter(Passage!="Pre-highlighted")

bf2<-ground_change_agg %>%
  filter(Passage!="Unmodified")

bf = ttestBF(formula = mean_acc ~ filter(Passage!="Pre-highlighted"), data = bf1)
bf


#GLMER model
#data was collected until the last day of the fall semester 2019 Decemeber13th. 
# loading needed libraries
#full_model=glmer(auto_acc~Passage+(1|ResponseId) + (1|Question), data=ground_change, family="binomial", control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
#fit full model

#m2<-read_rds(here("Brms", "brms_gw.rds.gz"))
                  
#c_main <- emmeans(m2, ~ FL_149_DO, type="response")

#c_main1=plot(c_main, horizontal =FALSE, colors="darkgreen")  + labs(x="Passage Type", y= "Probability Answering Question") + theme_bw(base_size = 14) + ggplot2::coord_cartesian(ylim = c(0, 1)) + theme(axis.text=bold)

#means<-estimate_means(full_model)

#ef1 <- effect("Passage", full_model) #take final glmer model 
#x1 <- as.data.frame(ef1)

#old <- element_text(face = "bold", color = "black", size = 14) #axis bold
#p<- ggplot(x1, aes(Passage, fit, fill=Passage))+ 
#  geom_bar(stat="identity", position="dodge") + 
#  geom_errorbar(aes(ymin=lower, ymax=upper), width=0.2, position=position_dodge(width=0.9),color="red") + theme_bw(base_size=14)+labs(y="Pr Recall ", x="Passage Type") + 
 # scale_fill_manual(values=c("grey", "yellow", "black"))+
#  theme(axis.text=bold, legend.position = "none") + ggplot2::coord_cartesian(ylim = c(0, 1))


p1<- ggplot(ground_change_agg, aes(Passage, mean_acc, fill=Passage))+
  geom_violin() + 
  geom_jitter2(width=0.11, alpha=.5)+ 
  geom_line(data=ls1,aes(y=emmean, group=1), size=1)+ 
  geom_pointrange(data=ls1, aes(y=emmean, ymin=lower.CL, ymax=upper.CL), size=1, color="white")+ 
  theme_bw(base_size=14)+
  labs(y="Pr Recall", x="Passage Type") + 
  theme(legend.position = "none") + 
  ggplot2::coord_cartesian(ylim = c(0, 1)) + 
  theme(axis.text=bold) 

p1

```


## Exploratory Analysis

In Experiment 2 we also asked students about their metacognitive awareness of the manipulations. Specifically we asked participants: "How likely is it that you will be able to recall material from the passage you just read on a scale of 0 (not likely to recall) to 100 (likely to recall) in 5 minutes?" Initial analyses suggest that the normal passages were given higher JOLs (*M* = 57.4, *SE* = 1.97) than the pre-highlighted passage (*M* = 50.3, *SE* = 1.97), t(525) = -7.08,  *p* = .023. There were no reliable differences between the pre-highlighted passage and Sans Forgetica (*M* = 53.8, *SE* = 1.97), *t*(525) = -3.52,  *p* = .415 or between the passage in Sans Forgetica and the passage presented normally, *t*(525) = 3.56,  *p* = .406. 

```{r, fig.align="center", fig.height=4, fig.width=8, fig.cap="Judgements of learning as a function of passage type.",  messages=FALSE, echo=FALSE, results="asis"}

jols=ground %>% 
  group_by(ResponseId, FL_149_DO)%>%
  summarise(jols=mean(Q163_1)) %>%
  ungroup() %>%
  dplyr::rename(Passage="FL_149_DO") %>% 
  mutate(Passage=ifelse(Passage=="Highlight", "Pre-highlighted",     ifelse(Passage=="Passage", "Sans Forgetica", "Unmodified")))


ground_change_agg<-ground %>%
  group_by(ResponseId, Passage) %>%
  summarise(mean_acc=mean(auto_acc))




jols$Passage <- factor(jols$Passage, level=c("Pre-highlighted", "Unmodified", "Sans Forgetica"))     


p1<- ggplot(jols, aes(Passage, jols, fill=Passage))+
  geom_violin() + 
  geom_jitter2(width=0.11, alpha=.5)+ 
  stat_summary(fun=mean, geom="point", shape="diamond", color="white", size=4, position = position_dodge(width = .7)) + 
   stat_summary(fun.data = mean_cl_normal, na.rm = TRUE, 
               geom = "errorbar", width = .2, color = "Black",
               position = position_dodge(width = .7)) + 
  theme_bw(base_size=14)+
  labs(y="Judgements of Learning", x="Passage Type") + 
  theme(legend.position = "none") + 
  theme(axis.text=bold) 



a1 <- aov_ez("ResponseId", "jols", jols, 
             between = c("Passage")) # one way

#plot the results


ls1 <- emmeans(a1, specs = "Passage") # get the simple effects test for signifcant interaction. 

flex1=pairs(ls1)

kable(flex1)
jols<-as.data.frame(jols)

#apa_beeplot(
#  data = jols
#  , id = "ResponseId"
#  , dv = "jols"
#  , ylab="Judements of Learning (%)"
#  , xlab="Passage Type"
#  , factors = c("Passage")
#  )
#pairs=as.data.frame(flex1)
#f=apa_table(pairs)
p1

```


Words presented in Sans Forgetica did not lead to better recall than words left unmodified or pre-highlighted. We did, however, observe better memory for pre-highlighted information compared to words presented unmodified or in a Sans Forgetica font. 

Examining metamemory judgments, we showed that a passage in Sans Forgetica font does not produce lower judgement of learning compared to unmodified or pre-highlighted passages. Interestingly, individuals gave lower JOLs to pre-highlighted information compared to materials presented in a normal font. One potential reason for pre-highlighted information receiving lower JOLs than the normal passage is that pre-highlighted information served to focus participants attention specific parts of the passage. Given the question, participants might have thought this would hinder them if tested over the passage as a whole. 

# Experiment 3

Experiment 1 and 2 looked at cued recall. A recent transfer-appropriate processing (TAP) framework has contextualized when difficulties are desirable and when they are not [@McDaniel2011]. Its essence emphasizes the qualitative mismatch of the evoked encoding processes of the applied difficulty (and by the material) with respect to the required retrieval processes of the memory test. Thus, one important aspect postulated by this framework denotes the specific encoding processes stimulated by the type of difficulty applied. For example, generating incomplete word-fragments within a text intensifies the processing of the word cue and the word surroundings that help to identify the word, thus enhancing proposition-specific encoding. In contrast, creating sentence coherency in a text with randomized sentences intensifies the processing of the relationships of information in the text, thus enhancing relational encoding [@McDaniel1994]. Consequently, the generation-task, which required word-generation, led to improved verbatim recall, but it was not desirable for relational test questions (and vice versa). These differently evoked encoding processes (proposition-specific versus relational) by the generation task predicted different memory effects. Extending this to disfluency, it is possible that the desirable effects of disfluency memory paradigms (e.g., recognition). Indeed, @Geller2018 [also see @Rosner2015] found positive effects of disfluency in recognition memory. It is possible then that Sans Forgetica serves to increase familiarity with a stimulus, while recollection is unchanged. This is tested in Experiment 3 by employing an old-new recognition test.

The pre-registration form for Experiment 3, which includes hypotheses, planned analyses, exclusion criteria, and sample size justification, can be found at: https://osf.io/ekqh5.

### Participants

We report how we determined our sample size, all data exclusions, all inclusion/exclusion criteria, whether inclusion/exclusion criteria were established prior to data analysis, all manipulations, and all measures in the study. Sixty participants (*N* = 60) participated for partial completion of course credit. Sample size was determined by a similar procedure to the above experiments. No participants had to be thrown out for failing to meet the exclusion criteria noted above. 

### Materials

Stimuli were 188 nouns taken from @Geller2018. All words were from the English Lexicon Project database (Balota et al., 2007). Both frequency (all words were high frequency; mean log HAL frequency = 9.2) and length (all words were four letters in length) were controlled. The full set of stimuli can be found at https://osf.io/dsxrc/. 

# Design and Procedure

The experiment employed a within-subject design. The factor of script type (Arial vs. Sans Forgetica) was manipulated within-subjects. We employed 188 words, 94 at study (47 in each script condition) and 188 at test (94 old and 94 new). This resulted in four counterbalanced lists. Lists were assigned to participants so that across participants each word occurred equally often in the four possible conditions: Arial-old, Arial-new, Sans Forgetica-old, Sans Forgetica-new. 

Word order was completely randomized, such that Arial and Sans Forgetica words were randomly intermixed in the study phase, and Arial and
Sans Forgetica old and new words were randomly intermixed in the test phase. All old words were presented at test in the same manner in which they
were presented at study; that is, Arial words during study were presented in Arial font at test, and Sans Forgetica words during study were presented in Sans Forgetica font at test.

The experiment was created and conducted using the Gorilla Experiment Builder ([@Anwyl-Irvine2020]; http://www.gorilla.sc). The experiment protocol and tasks are available to preview and copy from Gorilla Open Materials at https://gorilla.sc/open materials/72765.

After reading and signing a consent form, participants first completed the study phase. During the study phase, a fixation cross appeared at the center of the screen for 500 ms. The fixation cross was immediately replaced by a word in the same location. To continue to the next trial, participants pressed the continue button at the bottom of the screen. Each trial was self-paced. After the study phase, a short 3-minute distractor task was administered in which participants wrote down as many United States capitals as they could. Afterward, participants took an old-new recognition test. At test, a word appeared in the center of the screen that either had been presented during study (“old”) or had not been presented during study (“new”). Old words occurred in their original script, and following the counterbalancing procedure, each new word was presented in Arial font or Sans Forgetica font. For each word presented, participants chose from one of two boxes displayed on the screen: a box labeled “old” to indicate that they had named the word during study, and a box labeled “new” to indicate they did not remember naming the word. Words stayed on the screen until participants gave an “old” or “new” response. All words were individually randomized for each participant during both the study and test phases. After the experiment, participants were debriefed. The entire experiment took about 30 minutes to complete.

# Results and discussion

In recognition memory, signal detection theory has proven to be a very informative and efficient approach to analyzing binary accuracy data. However, considering the deficiency in precision and power in traditional analyses compared to mixed effects analyses, it is worth considering a generalized linear mixed effect approach to signal detection theory [@DeCarlo1998]. In its simplest from, SDT models are probit regressions. To estimate the SDT parameter of interest (d'), we fit a logistical mixed model (with a probit link) to participant responses (sayold; whether participants said "old" or "new") with fixed effects for actual status of the item (isold; whether the item was old vs. new) and condition (Arial vs. Sans Forgetica) and the interaction between the two with random intercepts for participants (*N*=60) and targets (*N*=188): oldnew=glmer(sayold~isold*condition+(1|Participant)+ (1|target)). The variables isold and condition were contrast coded (0.5, -0.5) to allow for the estimation of the interaction between isold and condition. Within this model, the fixed effect of condition is the difference in c between groups, and the interaction term isold:condition would describe the difference in d’ between conditions. We hypothesized that there would be no difference in d' between Sans Forgetica and Arial font. 

Hit rates and false alarm rates can be seen in Fig. 3. The results are straight-forward. Individuals were more biased to say Sans Forgetica stimuli were old, *b* = 0.26, *SE* = 0.026, 95% CI [0.217, 0.319], *p* < .005. Consistent with our hypothesis, there was no difference in d' between Sans Forgetica and Arial fonts, *b* = 0.033, *SE* = 0.05, 95% CI [-0.138, 0.065], *p* = .519. There was strong evidence for no effect (BF~01~ = 13.68). 

Similar to experiments 1 and 2, we did not find an effect of Sans Forgetica font on recognition memory. 

```{r, fig.align="center", fig.height=4, fig.width=8, fig.cap = "Mean proportions of “old” responses for Experiment 3. Violin plots represent the kernal density of average probability (black dots) with the fixed effect mean (white dot) and 95\\% CIs derived from the glmer model.", warning=FALSE,  messages=FALSE, echo=FALSE, results="asis"}
#frecog=read_csv(here("Expt3_data", "expt3recog.csv"))

#oldnew=glmer(sayold~isold*condition1+(1+isold*condition1|Participant.Private.ID)+ (1+isold*condition1|Stims), data=sfrecog, family=binomial(link="probit"))
data=here('Expt3_data', 'Gorilla_raw_data', 'ex3_recog.csv')  


ex3=read_csv(data)

oldnewglme=brm(sayold~isold*condition1+(1+isold*condition|Participant.Private.ID)+ (1+isold*condition|Stims), data=ex3, family=bernoulli(link="probit"))


means<-estimate_means(oldnewglme)


#recode Response as sayold and old.new as isold
ex3$isold=ifelse(ex3$old.new== "new", 0, 1)

#classic SDT for those wanting to compare
sdt <- ex3 %>% 
  dplyr::mutate(type = "hit",
         type = ifelse(isold==1 & sayold==0, "miss", type),
         type = ifelse(isold==0 & sayold==0, "cr", type),  # Correct rejection
         type = ifelse(isold==0 & sayold==1, "fa", type))  # False alarm

sdt <- sdt %>% 
  group_by(Participant.Private.ID, type, condition) %>% 
  summarise(count = n()) %>% 
  spread(type, count)  # Format data to one row per person

sdt <- sdt %>% 
  group_by(Participant.Private.ID, condition)%>%
  mutate(hr = hit / (hit+miss),
         fa = fa / (fa+cr),
         dprime = hr-fa,
         crit = -fa)

sdt1=sdt  %>% select(Participant.Private.ID, condition, hr, fa) %>% 
  pivot_longer(hr:fa, names_to="type") %>%
  mutate(isold=case_when(type=="hr" ~ "Old", type=="fa" ~ "New"), Condition=case_when(
  condition=="SF"~ "Sans Forgetica", 
  condition=="normal"~ "Arial"
))

sdt1$isold<-factor(sdt1$isold, levels=c("Old", "New"))

sdt1$Condition<-factor(sdt1$Condition, levels=c("Sans Forgetica", "Arial"))



means <- means %>% mutate(isold=case_when(
  old.new=="new"~ "New", 
  old.new=="old"~ "Old"), Condition=case_when(
  condition=="SF"~ "Sans Forgetica", 
  condition=="normal"~ "Arial"
))

means$isold<-factor(means$isold, levels=c("Old", "New")) 
means$Condition<-factor(means$Condition, levels=c("Sans Forgetica", "Arial"))
  
# path to data files

p1<- ggplot(sdt1, aes(Condition, value, fill=Condition))+
  facet_grid(~isold) + 
  geom_violin() + 
  geom_jitter2(width=0.11, alpha=.5)+ 
  geom_line(data=means,aes(y=Probability, group=1), size=1)+ 
  geom_pointrange(data=means, aes(y=Probability, ymin=CI_low, ymax=CI_high), size=1, color="white")+ 
  theme_bw(base_size=14)+
  labs(y="(Pr) saying Old", x="Font Type") + 
  theme(legend.position = "none") + 
  ggplot2::coord_cartesian(ylim = c(0, 1)) + 
  theme(axis.text=bold) 


#oldnew=brm(glmm2, data=ex3, family=bernoulli(link="identity"), prior=Priors, sample_prior = TRUE,  cores=6, inits = 0, control = list(adapt_delta = .9), iter=3000)

p1


```


```{r}
library(sjPlot)

tab_model(oldnewglme)

```
# Discussion

The purpose of the three experiments was to determine whether Sans Forgetica served as a desirable difficulty. The main finding from all three experiments is that Sans Forgetica is not a desirable difficulty. While it has been claimed in unpublished and published studies [@Eskenazi2020] that Sans Forgetica has a positive effect on memory, we report results from three high-powered memory experiments arguing against this claim. Specifically, we demonstrated that Sans Forgetica does not enhance recall for cue-target pairs (Experiment 1), words embedded in sentences from a passage (Experiment 2), or recognition memory (Experiment 3). This adds to the increasing literature showing that perceptual disfluency has very little impact on actual memory performance [e.g., @Magreehan2016; @Rhodes2008; @Rhodes2009; @Rummer2016; @Xie2018; @Yue2013]. Nonsurprisingly, we did observe a memory advantage for items that had to be generated (Experiment 1) and that were pre-highlighted (Experiment 2).

## Limitations

In order for perceptual disfluency to have an effect on memory it must be sufficently disfluent [@Geller2018; @Rosner2015]. In many studies perceptual disfluency is assumed, but never explicitly tested. Thus, it could be that the failure to observe an effect in the current set of studies is because Sans Forgetica font is not perceptually disfluent. Although we did not pre-register explicit hypotheses about the the perceptual disfluncy of the Sans Forgetica font, there is some  preliminary evidence that Sans Forgetica is not disfluent. In general, perceptual disfluency is thought to lower JOLs and produce longer latencies [@Geller2018; @Xie2018]. In Experiment 2, Sans Forgetica font did not produce lower JOLs. In Experiment 3, we collected self-paced reading times for each stimulus. Self-paced reading times have been used as an objective proxy for disfluency [see @Carpenter2020]. Looking at the difference in self-paced reading times, we did not observe a significant difference between Sans Forgetica (*M* = 1481 ms, *SD* = 1750 ms) and Arial (*M* = 1500 ms, *SD* = 2344 ms) fonts, *t*(59) = 0.469, *p* = 0.641. This could explain why we did not observe an effect of Sans Forgetica on memory across three experiments. 

There are a number of boundary conditions or moderating factors that determine whether perceptual disflunecy is desirable or not [@Eskenazi2020, @Geller2018, Geller & Still, 2018]. This makes it impossible to test ever single moderating factor in a single paper. We concede that it is possible that the Sans Forgetica effect does have positive effects, but is limited to a certain set of conditions. For instance, [@Eskenazi2020] showed that Sans Forgetica can have a desirable effect, but only if you are are a good speller. Better spellers are thought to have a more precise mental lexicon which allows for more efficient processing at multiple levels of representation (i.e,, orthographic, phonological, and semantic; Perfetti, 2007). When confronted with perceptual degradation, better spellers would be able to process a stimulus at a deeper level, which could give rise to better memory. It is unclear how this could explain some of the results obtained herein. For instance, in Experiment 3, we used high-frequency words that are well known. Nonetheless, future studies should examine spelling ability as a potential moderating factor into the perceptual disfluency effect. 

Lastly, it is possible that the effect size of the Sans Forgetica effect is smaller than we could detect across our three studies. We powered our studies to detect a medium-sized effect (*d*=.35). If the Sans Forgetica effect is small, it is not clear what the educational use for it would be. If more research is published, a meta-analysis can be conducted to determine the true effect size and any moderating factors of the Sans Forgetica effect. 

## Conclusion

The three experiments herein present evidence against claims put forth by its creators and the media [also see @Eskenazi2020]. We ultimately recommend caution in using Sans Forgetica font. Sans Forgetica does not enhance memory. Students looking to remember more and forget less should use other "power tools" shown to enhance learning. Sans Forgetica font is really forgettable. 


\newpage

# References
```{r create_r-references}
r_refs(file = "ref.bib")
```

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id = "refs"></div>
\endgroup
